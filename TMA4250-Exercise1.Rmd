--- 
title: "TMA4250 Spatial Statistics Exercise 1, Spring 2019"
output:
  pdf_document:
    toc: yes
    toc_depth: '2'
  word_document:
    toc: yes
    toc_depth: '2'
  html_document:
    toc: yes
    toc_depth: 2
    toc_float: yes
date: "`r format(Sys.time(), '%d.%m.%Y')`"
subtitle: 'Group members: Henrik Syversveen Lie, Ã˜yvind Auestad (SKRIVE STUDENTNUMMER
  I STEDET??)'
---


```{r setup, include = FALSE}
library(formatR)
showsol <- FALSE
library(knitr)
opts_chunk$set(tidy.opts = list(width.cutoff = 68), tidy = TRUE, warning = FALSE, error = FALSE, message = FALSE, echo = TRUE)
```

```{r, echo = F, eval = T}
library(reshape2)
library(geoR)
library(ggplot2)
library(MASS)
library(cowplot)
library(fields)
library(akima)
```

# Problem 1: Gaussian RF - model characteristics
We consider the continuous spatial variable $\{r(x):x\in D : [1,50] \subset \mathbb{R}^1$, and assume that it is modeled as a stationary 1D Gaussian RF with the following model parameters:
\begin{gather*}
\text{E}\{r(x)\} = \mu_r = 0\\
\text{Var}\{r(x)\} = \sigma_r^2\\
\text{Corr}\{r(x), r(x')\} = \rho_r(\tau),
\end{gather*}
where $\rho_r(\tau)$; $\tau = \rvert x-x'\lvert/10$ is the spatial correlation function. Let $D:[1,50]$
be discretised in $L \in \{1, 2,\dots , 50\}$ and define the discretised Gaussian RF
$\{r(x); x \in L\}$, represented by the $n$-vector $\mathbf{r}\in\mathbb{R}^n$. 


Let the spatial correlation function $\rho_r(\tau)$, be either Powered exponential with parameter $\nu_r \in [1, 1.9]$ or Matern with parameter $\nu_r \in [1, 3]$. Let the variance take the values $\sigma_r^2 \in [1, 5]$.

## a)
We restrict the spatial correlation functions to be only positive definite functions. Covariance matrices need to be positive definite, and a positive definite correlation function ensures that all covariances matrices in our stationary Gaussian RF are positive definite for all configurations and dimensions. Further, we define a function $\rho(\tau):\mathbb{R}^q\rightarrow \mathbb{R}$ to be positive definite if
\begin{align*}
&\sum_{i=1}^n\sum_{j=1}^n \alpha_i \alpha_j \rho(\mathbf{x}_i-\mathbf{x}_j) \geq 0,\\
&\text{for all configuations } [\mathbf{x}_1, \mathbf{x}_2,\ldots,\mathbf{x}_n]\in\mathbb{R}^{q\times n},\\
&\text{for all weights } \boldsymbol{\alpha} = (\alpha_1, \alpha_2,\ldots,\alpha_n)\in \mathbb{R}^n,\\
&\text{for all }n\in \mathbb{N}_+ \setminus \{1\}.
\end{align*}

To further investigate different correlation functions, we display two types of correlation functions, the Matern and Powered exponential functions, for different values of $\nu_r$. 

```{r, echo = F, eval = T, out.width = "50%", fig.align = "center"}
set.seed(123)
x = seq(0,5,length.out = 1001)
mat_1 = matern(x, 1, 1)
mat_2 = matern(x, 1, 3)
pexp_1 = cov.spatial(x, cov.model = "exponential", cov.pars = c(1, 1))
pexp_2 = cov.spatial(x, cov.model = "exponential", cov.pars = c(1, 1.9))
df = data.frame(y1 = mat_1, y2 = mat_2, y3 = pexp_1, y4 = pexp_2, value = x)
ggplot(df, aes(x, y = value, color = variable)) + 
  geom_line(aes(y = y1, colour = "y1")) +  
  geom_line(aes(y = y2, colour = "y2")) +
  geom_line(aes(y = y3, colour = "y3")) + 
  geom_line(aes(y = y4, colour = "y4")) + 
  scale_color_manual(labels = c(expression(paste("Matern ",nu, "=1")), expression(paste("Matern ",nu, "=3")),expression(paste("PExp ", nu, "=1")), expression(paste("PExp ", nu, "=1.9"))), values = c("red", "blue", "green", "purple")) + xlab(expression(paste(tau))) + ylab(expression(paste(rho, "(", tau,")"))) + ggtitle(expression(paste("Display of two correlation functions for different values of ", nu)))
```

For all correlation functions $\rho_r(0)  =1$, and $\rho_r(\tau) \in [-1,1]$; $\tau\in\mathbb{R}_+$, because the function represents correlation between two random variables. The correlation functions are continuous everywhere, except at $\tau = 0$ where a step may occur. If the correlation function is continuous at $\tau = 0$, then the random field is continuous almost everywhere. Away from $\tau = 0$, the correlation function must be smooth. From the displayed correlation functions, we see that $\rho_r(\tau)\rightarrow 0$ as $\tau \rightarrow \infty$. This will be the case for all correlation functions, implying that two points $\mathbf{x}$ and $\mathbf{x}'$ will tend towards being uncorrelated as $\lvert\mathbf{x}-\mathbf{x}'\rvert\rightarrow\infty$. Uncorrelated Gaussian random fields means that they will be independent, and by extension asymptotics Gaussion random fields are ergodic.

The correlation functions define correlation between points in our random field. This means that larger values of the correlation function implies a smoother random field. From the plotted correlation function, we see that the function values increases for larger values of $\nu_r$. Consequently, larger values of $\nu_r$ implies smoother random fields for both these correlation functions.

We now define the variogram function, which for stationary Gaussian random fields is defined as $\gamma_r(\tau) = 2\sigma^2_r[1-\rho_r(\tau)]$. Then, we display the variogram functions associated with the previously plotted correlation functions for $\sigma_r^2 = 1$.
```{r, echo = F, eval = T, out.width = "50%", fig.align = "center"}
gamma_1 = 2*(1-mat_1)
gamma_2 = 2*(1-mat_2)
gamma_3 = 2*(1-pexp_1)
gamma_4 = 2*(1-pexp_2)

df = data.frame(y1 = gamma_1, y2 = gamma_2, y3 = gamma_3, y4 = gamma_4, value = x)

ggplot(df, aes(x, y = value, color = variable)) + 
  geom_line(aes(y = y1, colour = "y1")) + 
  geom_line(aes(y = y2, colour = "y2")) +
  geom_line(aes(y = y3, colour = "y3")) + 
  geom_line(aes(y = y4, colour = "y4")) + 
  scale_color_manual(labels = c(expression(paste("Matern ",nu, "=1")), expression(paste("Matern ",nu, "=3")),expression(paste("PExp ", nu, "=1")), expression(paste("PExp ", nu, "=1.9"))), values = c("red", "blue", "green", "purple")) + xlab(expression(paste(tau))) + ylab(expression(paste(rho, "(", tau,")"))) + ggtitle(expression(paste("Variogram for two correlation functions for different values of ", nu)))+
  theme(legend.title=element_blank())
```

## b)
The prior Gaussion random field is defined on the discretized representation $L\in \{1,2,\dots,50\}$ by
$$\mathbf{r} \sim p(\mathbf{r}) = \phi_n(\mathbf{r};\mu_r \mathbf{i}_n, \sigma^2_r \boldsymbol{\Sigma}_r^\rho),$$
which is a discretized stationary Gaussian random field with expectation $\mu(\mathbf{x}) = \mu_r$, variance $\sigma^2(\mathbf{x}) = \sigma_r^2$ and correlation function $\rho(\mathbf{x},\mathbf{x}') = \rho_r(\mathbf{x}-\mathbf{x}')$.

We now want to simulate ten realizations of the Gaussian random field on $L$ for all the previously displayed correlation functions and $\sigma_r^2 \in [1,5]$.

```{r, echo = F, eval = T}
make_plot <- function(df,string){
  p <-ggplot(df, aes(x, y = value, color = variable)) + 
    geom_line(aes(y = X1, col = "x1")) + 
    geom_line(aes(y = X2, col = "x2")) +
    geom_line(aes(y = X3, col = "x3")) + 
    geom_line(aes(y = X4, col = "x4")) + 
    geom_line(aes(y = X5, col = "x5")) + 
    geom_line(aes(y = X6, col = "x6")) +
    geom_line(aes(y = X7, col = "x7")) + 
    geom_line(aes(y = X8, col = "x8")) +    
    geom_line(aes(y = X9, col = "x9")) + 
    geom_line(aes(y = X10, col = "x10"))+  theme(legend.position = "none",axis.title.x=element_blank(),
        axis.text.x=element_blank(),axis.title.y=element_blank(), plot.title = element_text(size=12))  +
    ggtitle(string)
  return(p)
}

x = seq(1,50)
tau = abs(outer(x,x,'-')/10)
mu_r = rep(0,50)

sigmamatrix1 = matern(tau,1,1)
sample1 = mvrnorm(10,mu_r,sigmamatrix1)
df = data.frame(x, t(sample1))
p1 <- make_plot(df, expression(paste("Matern, ", nu, "=1, ", sigma, "=1")))

sigmamatrix2 = 5*matern(tau,1,1)
sample2 = mvrnorm(10,mu_r,sigmamatrix2)
df = data.frame(x, t(sample2))
p2 <- make_plot(df, expression(paste("Matern, ", nu, "=1, ", sigma, "=5")))

sigmamatrix3 = matern(tau,1,3)
sample3 = mvrnorm(10,mu_r,sigmamatrix3)
df = data.frame(x, t(sample3))
p3 <- make_plot(df, expression(paste("Matern, ", nu, "=3, ", sigma, "=1")))

sigmamatrix4 = 5*matern(tau,1,3)
sample4 = mvrnorm(10,mu_r,sigmamatrix4)
df = data.frame(x, t(sample4))
p4 <- make_plot(df, expression(paste("Matern, ", nu, "=3, ", sigma, "=5")))

sigmamatrix5 = cov.spatial(tau, cov.model = "exponential", cov.pars = c(1, 1))
sample5 = mvrnorm(10,mu_r,sigmamatrix5)
df = data.frame(x, t(sample5))
p5 <- make_plot(df, expression(paste("PExp, ", nu, "=1, ", sigma, "=1")))

sigmamatrix6 = 5*cov.spatial(tau, cov.model = "exponential", cov.pars = c(1, 1))
sample6 = mvrnorm(10,mu_r,sigmamatrix6)
df = data.frame(x, t(sample6))
p6 <- make_plot(df, expression(paste("PExp, ", nu, "=1, ", sigma, "=5")))

sigmamatrix7 = cov.spatial(tau, cov.model = "exponential", cov.pars = c(1, 1.9))
sample7 = mvrnorm(10,mu_r,sigmamatrix7)
df = data.frame(x, t(sample7))
p7 <- make_plot(df, expression(paste("PExp, ", nu, "=1.9, ", sigma, "=1")))

sigmamatrix8 = 5*cov.spatial(tau, cov.model = "exponential", cov.pars = c(1, 1.9))
sample8 = mvrnorm(10,mu_r,sigmamatrix8)
df = data.frame(x, t(sample8))
p8 <- make_plot(df, expression(paste("PExp, ", nu, "=1.9, ", sigma, "=5")))


plot_grid(p1,p2, p3, p4, p5, p6, p7, p8,nrow = 2, ncol = 4)
```

From the display, we see that a greater value of $\nu_r$ leads to smoother random fields. Also, a higher value of $\sigma_r^2$ leads to larger variations around the expected level $\mu_r = 0$. Also, the Matern correlation function leads to smoother random fields than the Powered exponential function.


## c)
We now observe the spatial variable as $\{d(x);x\in[10,25,30]\subset L\}$ according to the acquisition model,
$$d(x) = r(x) + \epsilon(x) \quad \quad x\in[10,25,30],$$
with measurement errors $\epsilon(\cdot)$ centred, i.i.d Gaussian with variance $\sigma_\epsilon^2$. Further, we assume that $r(x)$ and $r(x')$ are independent for all $x, x'$.

The likelihood model $p(\mathbf{d}|\mathbf{r})$ links the observations to the spatial variable. The observations $\mathbf{d}$ are known, while $\mathbf{r}$ is the spatial variable. This means that the likelihood $p(\mathbf{d}|\mathbf{r})$ is not a pdf w.r.t. $\mathbf{r}$, and we do not need to normalize the likelihood.

We can define a Gauss-linear likelihood model relative to the discretized spatial variable $\mathbf{r}$, and observe $\mathbf{d}\in\mathbb{R}^m$ according to
$$[\mathbf{d}|\mathbf{r}] = \mathbf{H}\mathbf{r} + \boldsymbol \epsilon_{d|r} \sim p(\mathbf{d}|\mathbf{r}) = \phi_m(\mathbf{d};\mathbf{H}\mathbf{r},\boldsymbol \Sigma_{d|r}),$$
where $\mathbf{H}$ is a $(m\times n)$ observation matrix. In our case, because we have three observations, $m = 3$. Also, the observations are assumed to have i.i.d. errors, which implies $\boldsymbol \Sigma_{d|r} = \sigma_\epsilon^2 I_{m\times m}$.

## d)
The pdf for the discretised posterior Gaussian random field, given the observations is defined in the following way,
$$[\mathbf{r}|\mathbf{d}]\sim p(\mathbf{r}|\mathbf{d}) = \phi_n(\mathbf{r};\boldsymbol \mu_{r|d},\boldsymbol \Sigma_{r|d},)$$
with
\begin{align*}
\boldsymbol \mu_{r|d} &=\mu_r \mathbf{i}_n + \sigma^2_r \boldsymbol \Sigma_r^\rho \mathbf{H}^T\big[\sigma_r^2\mathbf{H}\boldsymbol \Sigma_r^\rho\mathbf{H} + \boldsymbol \Sigma_{d|r}\big]^{-1}[\mathbf{d}-\mu_r\mathbf{H}\mathbf{i}_n]\\
\boldsymbol \Sigma_{r|d} &= \boldsymbol \Sigma_{r|d}^\sigma \boldsymbol \Sigma_{r|d}^\rho \boldsymbol \Sigma_{r|d}^\sigma = \sigma_r^2 \boldsymbol \Sigma_r^\rho - \sigma_r^2 \boldsymbol \Sigma_r^\rho\mathbf{H}^T\big[\sigma_r^2\mathbf{H}\boldsymbol \Sigma_r^\rho\mathbf{H} + \boldsymbol \Sigma_{d|r}\big]^{-1}\sigma_r^2\mathbf{H}\boldsymbol \Sigma_r^\rho
\end{align*}

We use as prior model one of the realizations with $\sigma_r^2 = 5$, $\nu = 1$ and Matern correlation function. Then, a prediction of the spatial variable $\{\hat{r}(\mathbf{x}); \mathbf{x}\in L\}$ represented by the vector $\hat{\mathbf{r}}$ is taken to minimize squared error, yielding
$$\hat{\mathbf{r}} = \mathbf{E}[\mathbf{r}|\mathbf{d}] = \boldsymbol \mu_{r|d}.$$
The associated $(1-\alpha)$ prediction intervals are,
$$PI_\alpha = \boldsymbol \mu_{r|d} \pm z_{\alpha/2} \boldsymbol \sigma_{r|d},$$
where $\boldsymbol \sigma_{r|d}$ is a $n$-vector containing the diagonal elements of the standard deviation matrix $\boldsymbol \Sigma_{r|d}^\sigma$.

We compute and plot both the prediction and the interval.

```{r, echo = F, eval = T, out.width = '50%'}
sample = sample2[2,]
sigma_r_rho = sigmamatrix2
observation = c(sample[10], sample[25], sample[30])
H = matrix(0, nrow = 3, ncol = 50)
H[1,10] = 1
H[2,25] = 1
H[3,30] = 1
sigma_e = 0
sigma_dr = diag(3)*sigma_e
mu_rd_zero = mu_r + 5*sigma_r_rho%*%t(H)%*%solve(5*H%*%sigma_r_rho%*%t(H)+sigma_dr)%*%(observation-H%*%mu_r)
sigma_rd_zero = 5*sigma_r_rho-5*sigma_r_rho%*%t(H)%*%solve(5*H%*%sigma_r_rho%*%t(H)+sigma_dr)%*%H%*%sigma_r_rho*5
std_rd_zero = sqrt(diag(sigma_rd_zero))
std_rd_zero[30] = 0
std_rd_zero[25] = 0
std_rd_zero[10] = 0
lower_bound = mu_rd_zero - qnorm(0.95)*std_rd_zero
upper_bound = mu_rd_zero + qnorm(0.95)*std_rd_zero


df = data.frame(y1 = mu_rd_zero, y2 = c(rep(NA,9), observation[1], rep(NA,14), observation[2], rep(NA,4), observation[3], rep(NA,20)), y3 = lower_bound, y4 = upper_bound)
ggplot(df, aes(x, y = value, color = variable)) + 
    geom_line(aes(y = y1, col = "y1")) + 
    geom_point(aes(y = y2, col = "y2")) + 
    geom_line(aes(y = y3, col = "y3"), linetype = "dashed") + 
    geom_line(aes(y = y4, col = "y4"), linetype = "dashed") +
    scale_colour_manual(labels = c("Prediction", "Observations", "Lower bound", "Upper bound"), values = c("Red", "black", "blue", "green")) + ggtitle(bquote("Prediction of r(x) with 90% prediction interval and "*sigma[epsilon]^2*"=0"))+
  theme(legend.position = 'none')

sigma_e = 0.25
sigma_dr = diag(3)*sigma_e
mu_rd_nonzero = mu_r + 5*sigma_r_rho%*%t(H)%*%solve(5*H%*%sigma_r_rho%*%t(H)+sigma_dr)%*%(observation-H%*%mu_r)
sigma_rd_nonzero = 5*sigma_r_rho-5*sigma_r_rho%*%t(H)%*%solve(5*H%*%sigma_r_rho%*%t(H)+sigma_dr)%*%H%*%sigma_r_rho*5
std_rd_nonzero = sqrt(diag(sigma_rd_nonzero))
lower_bound = mu_rd_nonzero - qnorm(0.95)*std_rd_nonzero
upper_bound = mu_rd_nonzero + qnorm(0.95)*std_rd_nonzero

df = data.frame(y1 = mu_rd_nonzero, y2 = c(rep(NA,9), observation[1], rep(NA,14), observation[2], rep(NA,4), observation[3], rep(NA,20)), y3 = lower_bound, y4 = upper_bound)
ggplot(df, aes(x, y = value, color = variable)) + 
    geom_line(aes(y = y1, col = "y1")) + 
    geom_point(aes(y = y2, col = "y2")) + 
    geom_line(aes(y = y3, col = "y3"), linetype = "dashed") + 
    geom_line(aes(y = y4, col = "y4"), linetype = "dashed") +
    scale_colour_manual(labels = c("Prediction", "Observations", "Lower bound", "Upper bound"), values = c("Red", "black", "blue", "green")) + ggtitle(bquote("Prediction of r(x) with 90% prediction interval and "*sigma[epsilon]^2*"=0.25"))+
  theme(legend.title=element_blank())
```

From the plots, we see that with no observation error, the prediction coincides with the observations in the points where we have an observation. Also, in these points there is no uncertainty, so the lower and upper bounds are also equal the observations. When observation error is present, we get uncertainty in the observed points. In addition, adding an observation error leads to larger uncertainty, and thus variance, over the entire prediction.

## e)
We now go on to simulate 100 realizations from the posterior distribution, using the mean and covariance matrix previously computed. Then, we make a prediction based on the 100 samples and create a 90% prediction interval by computing the empirical variance.

```{r, echo = F, eval = T,out.width = "50%"}
sample = mvrnorm(100, mu_rd_zero, sigma_rd_zero)
prediction = apply(sample,2,mean)
std_empirical = sqrt(apply(sample,2,var))
lower = prediction - qt(0.95,99)*std_empirical*sqrt(1+1/100)
upper = prediction + qt(0.95,99)*std_empirical*sqrt(1+1/100)

rownames(sample) = paste("trial", seq(100), sep="")
colnames(sample) = paste("x", seq(50), sep="")

dat = as.data.frame(sample)
dat$trial = rownames(dat)
mdat = melt(dat, id.vars="trial")
mdat$x = as.numeric(gsub("x", "", mdat$variable))
df = data.frame(x = seq(1,50), pred = prediction, lb = lower, ub = upper)

ggplot() +
    theme_bw() +
    theme(panel.grid=element_blank()) +
    geom_line(data = mdat, aes(x=x, y=value, group=trial), size=0.2, alpha=0.1) +
    geom_line(data = df, aes(x = x, y = pred), size = 1, col = 'red') + 
    geom_line(data = df, aes(x = x, y = lb), size = 1, col = 'blue', linetype = "dashed") + 
    geom_line(data = df, aes(x = x, y = ub), size = 1, col = 'blue', linetype = "dashed") + 
    ggtitle(bquote("Prediction and 100 realizations of posterior Gaussian RF with "*sigma[epsilon]^2*"=0"))

sample = mvrnorm(100, mu_rd_nonzero, sigma_rd_nonzero)


prediction = apply(sample,2,mean)
std_empirical = sqrt(apply(sample,2,var))
lower = prediction - qt(0.95,99)*std_empirical*sqrt(1+1/100)
upper = prediction + qt(0.95,99)*std_empirical*sqrt(1+1/100)


rownames(sample) = paste("trial", seq(100), sep="")
colnames(sample) = paste("x", seq(50), sep="")

dat = as.data.frame(sample)
dat$trial = rownames(dat)
mdat = melt(dat, id.vars="trial")
mdat$x = as.numeric(gsub("x", "", mdat$variable))
df = data.frame(x = seq(1,50), pred = prediction, lb = lower, ub = upper)

ggplot() +
    theme_bw() +
    theme(panel.grid=element_blank()) +
    geom_line(data = mdat, aes(x=x, y=value, group=trial), size=0.2, alpha=0.1) +
    geom_line(data = df, aes(x = x, y = pred), size = 1, col = 'red') + 
    geom_line(data = df, aes(x = x, y = lb), size = 1, col = 'blue', linetype = "dashed") + 
    geom_line(data = df, aes(x = x, y = ub), size = 1, col = 'blue', linetype = "dashed") + 
    ggtitle(bquote("Prediction and 100 realizations of posterior Gaussian RF with "*sigma[epsilon]^2*"=0.25"))
```

Discuss the relation between the model parameters and the realizations,
and discuss the relation between the analytically and empirically obtained
predictions with prediction intervals!!!!!!!!!

## f)
SPØR OM DENNE!!!!

We use the previously generated 100 realizations with $\sigma_\epsilon^2 = 0$ to provide a prediction $\hat{A}_r$ for the non-linear function on $\{r(x);x\in D\}$,
$$A_r = \int_D I(r(x)>2)dx.$$
We also compute the prediction variance. An alternative predictor is,
$$\tilde{A}_r = \sum_{x\in L} I(\hat{r}(x)>2).$$
This is also computed.

```{r, echo = F, eval = T}
extract <- function(sample){
  return(length(sample[which(sample>2)]))
}
A_hat = apply(sample, 1,extract)
cat("A hat: ", mean(A_hat), '\n')

sigma_r_rho = sigmamatrix2
observations = matrix(c(sample2[,10], sample2[,25], sample2[,30]), nrow = 10, ncol = 3)
sigma_e = 0
sigma_dr = diag(3)*sigma_e
r_hat = 5*sigma_r_rho%*%t(H)%*%solve(5*H%*%sigma_r_rho%*%t(H)+sigma_dr)%*%t(observations)
A_tilde = apply(r_hat,2,extract)

cat("A tilde: ", mean(A_tilde), '\n')
cat("Predicted variance of A hat: ", var(A_hat))
```
Jensen's inequality states that for a random variable $X$ and a convex function $\psi$,
$$\psi(E[X]) \leq E[\psi(X)].$$
Taking $X = r(x)$ and $\psi(\xi) = I(\xi >2)$, this implies,???
## g)

# Problem 2: Gaussian RF - real data

## a)

## b)

```{r, echo = F, eval = T, out.width = "50%", fig.align = "center"}
x = rep(seq(0, 315, length.out = ),30)
y = rep(seq(1, 30, length.out = 30),each = 30)
dat = matrix(c(x,y), nrow = 900, ncol = 2)
distances = dist(dat)
distances <- as.matrix(distances)
sigma_r = 2
xi_r = 15
corr <- function(x, xi){
  return(exp(-x/xi))
}
corrmatrix = corr(distances, xi_r)
covmatrix = sigma_r*corrmatrix
mu_r = rep(0,900)
sample = mvrnorm(1,mu_r,covmatrix)
mtrx3d <- data.frame(x = x, y = y, z = sample)
mtrx.melt <- melt(mtrx3d, id.vars = c("x","y"), measure.vars = "z")
ggplot(mtrx.melt, aes(x = x, y = y, z = value)) +
         geom_raster(aes(fill = value))
```



#
```{r, echo = F, eval = T}
data = read.table("https://www.math.ntnu.no/emner/TMA4250/2017v/Exercise1/topo.dat")
interpolation <- interp(data$x, data$y, data$z)
contour(x = interpolation$x, y =interpolation$y, z = interpolation$z, drawlabels = F)

x = rep(interpolation$x,length(interpolation$x))
y = rep(interpolation$y,each = length(interpolation$y))
mtrx3d <- data.frame(x = x, y = y, z = as.vector(interpolation$z))
mtrx.melt <- melt(mtrx3d, id.vars = c("x","y"), measure.vars = "z")
ggplot(mtrx.melt, aes(x = x, y = y, z = value)) +
         geom_raster(aes(fill = value))
```
# Problem 3: Parameter estimation
## a)

```{r, echo = F, eval = T, out.width = "50%", fig.align = "center"}
x = rep(seq(1, 30, length.out = 30),30)
y = rep(seq(1, 30, length.out = 30),each = 30)
dat = matrix(c(x,y), nrow = 900, ncol = 2)
distances = dist(dat)
distances <- as.matrix(distances)
sigma_r = 2
xi_r = 15
corr <- function(x, xi){
  return(exp(-x/xi))
}
corrmatrix = corr(distances, xi_r)
covmatrix = sigma_r*corrmatrix
mu_r = rep(0,900)
sample = mvrnorm(1,mu_r,covmatrix)
mtrx3d <- data.frame(x = x, y = y, z = sample)
mtrx.melt <- melt(mtrx3d, id.vars = c("x","y"), measure.vars = "z")
ggplot(mtrx.melt, aes(x = x, y = y, z = value)) +
         geom_raster(aes(fill = value))
```


## b)
```{r, echo = F, eval = T}
vario <- variog(messages = F, coords = dat, data = sample)
df <- data.frame(x = seq(0,40))
df$y = sigma_r*(1-corr(df$x, xi_r))
df2 <- data.frame(v = vario$v, u = vario$u)
ggplot() + 
  geom_line(data = df, aes(x = x, y = y, colour = "Theoretical")) +  
  geom_point(data = df2, aes(y = v, x = u, colour = "Empirical")) + 
  xlab(expression(paste(tau))) + ylab("Variogram") + ggtitle("Comparison of empirical and theoretical variogram")
```


## c)


```{r, echo = F, eval = T}
n_obs = 36
obs36 <- unique(ceiling(runif(n_obs,0,900)))
while(length(obs36)<n_obs){
  obs36 <- unique(c(obs36,ceiling(runif(1,0,900))))
}
x_loc36 <- obs36%%30
y_loc36 <- obs36%/%30+1
coordinates = matrix(c(x_loc36,y_loc36), nrow = n_obs, ncol = 2)

datapoints = sample[obs36]
vario2 <- variog(messages = F,coords = coordinates, data = datapoints)
df <- data.frame(x = seq(0,max(as.matrix(dist(coordinates)))))
df$y = sigma_r*(1-corr(df$x, xi_r))
df2 <- data.frame(v = vario2$v, u = vario2$u)
ggplot() + 
  geom_line(data = df, aes(x = x, y = y, colour = "Theoretical")) +  
  geom_point(data = df2, aes(y = v, x = u, colour = "Empirical")) + 
  xlab(expression(paste(tau))) + ylab("Variogram") + ggtitle("Comparison of empirical and theoretical variogram")
```


```{r, echo = F, eval = T}

parameters <- likfit(messages = F, coords = dat, data = sample, ini.cov.pars = c(3,20), cov.model = "exponential")
parameters2 <- likfit(messages = F, coords = coordinates, data = datapoints, ini.cov.pars = c(3,20), cov.model = "exponential")

df <- data.frame(x = seq(0,40))
df$y1 = sigma_r*(1-corr(df$x, xi_r))
df$y2 = parameters$cov.pars[1]*(1-corr(df$x,parameters$cov.pars[2]))
df$y3 = parameters2$cov.pars[1]*(1-corr(df$x,parameters2$cov.pars[2]))
ggplot() + 
  geom_line(data = df, aes(x = x, y = y1, colour = "Theoretical")) +  
  geom_line(data = df, aes(y = y2, x = x, colour = "Full")) +
  geom_line(data = df, aes(y = y3, x = x, colour = "Partial36")) +
  xlab(expression(paste(tau))) + ylab("Variogram") + ggtitle("Comparison of maxlik... and theoretical variogram")
```


```{r, echo = F, eval = T, out.width = "33%"}
n_obs = 9
obs9 <- unique(ceiling(runif(n_obs,0,900)))
while(length(obs9)<n_obs){
  obs9 <- unique(c(obs9,ceiling(runif(1,0,900))))
} 
x_loc9 <- obs9%%30
y_loc9 <- obs9%/%30+1
coordinates9 = matrix(c(x_loc9,y_loc9), nrow = n_obs, ncol = 2)
datapoints9 = sample[obs9]

parameters9 <- likfit(messages = F, coords = coordinates9, data = datapoints9, ini.cov.pars = c(1,10), cov.model = "exponential")
vario9 <- variog(messages = F, coords = coordinates9, data = datapoints9)
df2 <- data.frame(v = vario9$v, u = vario9$u) 

df <- data.frame(x = seq(0,40))
df$y1 = sigma_r*(1-corr(df$x, xi_r))
df$y2 = parameters$cov.pars[1]*(1-corr(df$x,parameters$cov.pars[2]))
df$y3 = parameters9$cov.pars[1]*(1-corr(df$x,parameters9$cov.pars[2]))
v1<-ggplot() + 
  geom_line(data = df, aes(x = x, y = y1, colour = "Theoretical")) +  
  geom_line(data = df, aes(y = y2, x = x, colour = "Full")) +
  geom_line(data = df, aes(y = y3, x = x, colour = "Partial9")) +
  geom_point(data = df2, aes(y = v, x = u, colour = "Empirical")) + 
  xlab(expression(paste(tau))) + ylab("Variogram") + ggtitle("Comparison of maxlik... and theoretical variogram")

n_obs = 64
obs64 <- unique(ceiling(runif(n_obs,0,900)))
while(length(obs64)<n_obs){
  obs64 <- unique(c(obs64,ceiling(runif(1,0,900))))
} 
x_loc64 <- obs64%%30
y_loc64 <- obs64%/%30+1
coordinates64 = matrix(c(x_loc64,y_loc64), nrow = n_obs, ncol = 2)
datapoints64 = sample[obs64]


parameters64 <- likfit(messages = F,coords = coordinates64, data = datapoints64, ini.cov.pars = c(1,10), cov.model = "exponential")
vario64 <- variog(messages = F, coords = coordinates64, data = datapoints64)
df2 <- data.frame(v = vario64$v, u = vario64$u) 

df <- data.frame(x = seq(0,40))
df$y1 = sigma_r*(1-corr(df$x, xi_r))
df$y2 = parameters$cov.pars[1]*(1-corr(df$x,parameters$cov.pars[2]))
df$y3 = parameters64$cov.pars[1]*(1-corr(df$x,parameters64$cov.pars[2]))
v2<-ggplot() + 
  geom_line(data = df, aes(x = x, y = y1, colour = "Theoretical")) +  
  geom_line(data = df, aes(y = y2, x = x, colour = "Full")) +
  geom_line(data = df, aes(y = y3, x = x, colour = "Partial64")) +
  geom_point(data = df2, aes(y = v, x = u, colour = "Empirical")) + 
  xlab(expression(paste(tau))) + ylab("Variogram") + ggtitle("Comparison of maxlik... and theoretical variogram")

n_obs = 100
obs100 <- unique(ceiling(runif(n_obs,0,900)))
while(length(obs100)<n_obs){
  obs100 <- unique(c(obs100,ceiling(runif(1,0,900))))
} 
x_loc100 <- obs100%%30
y_loc100 <- obs100%/%30+1
coordinates100 = matrix(c(x_loc100,y_loc100), nrow = n_obs, ncol = 2)
datapoints100 = sample[obs100]

parameters100 <- likfit(messages = F,coords = coordinates100, data = datapoints100, ini.cov.pars = c(1,10), cov.model = "exponential")
vario100 <- variog(messages = F, coords = coordinates100, data = datapoints100)
df2 <- data.frame(v = vario100$v, u = vario100$u)

df <- data.frame(x = seq(0,40))
df$y1 = sigma_r*(1-corr(df$x, xi_r))
df$y2 = parameters$cov.pars[1]*(1-corr(df$x,parameters$cov.pars[2]))
df$y3 = parameters100$cov.pars[1]*(1-corr(df$x,parameters100$cov.pars[2]))
v3<-ggplot() + 
  geom_line(data = df, aes(x = x, y = y1, colour = "Theoretical")) +  
  geom_line(data = df, aes(y = y2, x = x, colour = "Full")) +
  geom_line(data = df, aes(y = y3, x = x, colour = "Partial100")) +
  geom_point(data = df2, aes(y = v, x = u, colour = "Empirical")) + 
  xlab(expression(paste(tau))) + ylab("Variogram") + ggtitle("Comparison of maxlik... and theoretical variogram")
v1
v2
v3
```



